{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1604da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01 â€“ Data Collection & Initial Cleaning\n",
    "#\n",
    "# In this notebook we:\n",
    "# - Load sample stock price files from data/stocks_sample/\n",
    "# - Load the fraud transactions dataset from data/fraud_dataset.csv\n",
    "# - Apply basic cleaning using src/data_cleaning.py\n",
    "# - Save intermediate cleaned datasets for later notebooks\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from src.data_cleaning import (\n",
    "    list_stock_files,\n",
    "    load_all_stocks,\n",
    "    clean_stock_data,\n",
    "    load_fraud_data,\n",
    "    clean_fraud_data,\n",
    "    save_cleaned_data,\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Paths\n",
    "# -------------------------------------------------------------------\n",
    "DATA_DIR = os.path.join(\"..\", \"data\")\n",
    "STOCK_DIR = os.path.join(DATA_DIR, \"stocks_sample\")\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"STOCK_DIR:\", STOCK_DIR)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Load Raw Stock Data\n",
    "# -------------------------------------------------------------------\n",
    "stock_files = list_stock_files(STOCK_DIR)\n",
    "print(\"\\nFound stock files:\")\n",
    "for f in stock_files:\n",
    "    print(\" -\", os.path.basename(f))\n",
    "\n",
    "stocks_raw = load_all_stocks(STOCK_DIR, date_col=\"date\")\n",
    "print(\"\\nRaw stocks shape:\", stocks_raw.shape)\n",
    "display(stocks_raw.head())\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Clean Stock Data\n",
    "# -------------------------------------------------------------------\n",
    "stocks_clean = clean_stock_data(\n",
    "    stocks_raw,\n",
    "    price_cols=[\"open\", \"high\", \"low\", \"close\"],\n",
    "    volume_col=\"volume\",\n",
    "    min_volume=0.0,\n",
    ")\n",
    "\n",
    "print(\"\\nCleaned stocks shape:\", stocks_clean.shape)\n",
    "display(stocks_clean.head())\n",
    "\n",
    "# Save cleaned stocks\n",
    "clean_stocks_path = os.path.join(DATA_DIR, \"cleaned_stocks.csv\")\n",
    "save_cleaned_data(stocks_clean, clean_stocks_path)\n",
    "print(\"\\nSaved cleaned stocks to:\", clean_stocks_path)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Load Fraud Dataset\n",
    "# -------------------------------------------------------------------\n",
    "fraud_raw_path = os.path.join(DATA_DIR, \"fraud_dataset.csv\")\n",
    "fraud_raw = load_fraud_data(fraud_raw_path)\n",
    "\n",
    "print(\"\\nRaw fraud dataset shape:\", fraud_raw.shape)\n",
    "display(fraud_raw.head())\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Clean Fraud Dataset\n",
    "# -------------------------------------------------------------------\n",
    "cols_to_drop = [\"customer_name\", \"customer_email\"]  # dropped only if they exist\n",
    "\n",
    "fraud_clean = clean_fraud_data(\n",
    "    fraud_raw,\n",
    "    target_col=\"is_fraud\",\n",
    "    drop_cols=cols_to_drop,\n",
    ")\n",
    "\n",
    "print(\"\\nCleaned fraud dataset shape:\", fraud_clean.shape)\n",
    "display(fraud_clean.head())\n",
    "\n",
    "# Save cleaned fraud data\n",
    "clean_fraud_path = os.path.join(DATA_DIR, \"cleaned_fraud_dataset.csv\")\n",
    "save_cleaned_data(fraud_clean, clean_fraud_path)\n",
    "print(\"\\nSaved cleaned fraud dataset to:\", clean_fraud_path)\n",
    "\n",
    "print(\"\\n=== 01_data_collection completed ===\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
